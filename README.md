# Device Simulator app

A FastAPI app that simulates IoT devices, utilizing Redis for data storage and state management. This project features a robust API for device interaction, comprehensive testing using pytest, and clear configuration management.

## Table of Contents

- [Features](#features)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Configuration](#configuration)
  - [Environment Variables](#environment-variables)
- [Installation](#installation)
- [Running the Application](#running-the-application)
- [API Endpoints](#api-endpoints)
- [Interactive API Documentation](#interactive-api-documentation)
- [Running Tests](#running-tests)
  - [Running All Tests](#running-all-tests)
  - [Running Specific Tests or Markers](#running-specific-tests-or-markers)
  - [Benchmark Tests](#benchmark-tests)
  - [Test Reports](#test-reports)
- [Fixture Design Decisions](#fixture-design-decisions)
- [Key Design Choices and Assumptions](#key-design-choices-and-assumptions)
- [Continuous Integration (CI)](#continuous-integration-ci)


## Features

- **Device Simulation**: Simulates IoT devices with states (online/offline) and attributes.
- **RESTful API**: Provides endpoints for listing devices, retrieving specific device details, and sending commands.
- **Redis Integration**: Uses Redis for persistent storage of device information, status, and command history.
  - Efficient data retrieval using Redis Hashes for device data.
  - Command logging using Redis Lists with capped history.
- **Asynchronous Operations**: Built with FastAPI for high-performance asynchronous request handling.
- **Data Validation**: Utilizes Pydantic models for request and response validation.
- **Configuration Management**: Centralized application settings using Pydantic's BaseSettings.
- **Comprehensive Testing**: Extensive test suite using pytest, including unit, integration, and performance benchmark tests.
- **OpenAPI Documentation**: Automatically generated and interactive API documentation (Swagger UI and ReDoc).
- **Connection Pooling**: Efficiently manages Redis connections using a connection pool.
- **Lifespan Management**: Handles application startup (e.g., Redis pool initialization) and shutdown events.
- **CI/CD Ready**: Includes a GitHub Actions workflow for automated testing.

## Project Structure

```
.
├── .github/                # GitHub Actions CI workflows
│   └── workflows/
│       └── tests-ci.yml
├── app.py                  # Main FastAPI application logic and endpoint definitions
├── assets/                 # Static assets (e.g., CSS for HTML reports)
│   └── style.css
├── config/                 # Configuration files
│   └── app_config.py       # Pydantic settings management
├── tests/                  # Pytest test suite
│   ├── conftest.py         # Pytest fixtures and hooks
│   ├── test_command_device_endpoint.py
│   ├── test_devices_endpoint.py
│   ├── test_general_app_performance.py
│   ├── test_health_endpoint_and_schema.py
│   ├── test_specific_device_endpoint.py
├── utils/                  # Utility modules
│   ├── data_models.py      # Pydantic data models
│   └── redis_helper.py     # Helper functions for Redis interactions
├── .env.example            # Example environment file (rename to .env and customize)
├── pytest.ini              # Pytest configuration file
├── README.md               # This file
├── requirements.txt        # Python package dependencies
└── report.html             # Example of an HTML test report (generated by pytest-html)
```

## Prerequisites

- Python 3.8+
- Redis server (version 5.x or later recommended)
- Access to a terminal or command prompt
- pip for installing Python packages

## Configuration

The application is configured primarily through environment variables. A `.env` file can be used to manage these variables locally.

**Create a `.env` file:**

Copy the `.env.example` file (if provided, otherwise create a new one) to `.env` in the project root:

```bash
cp .env.example .env
```

**Customize `.env`:**

Modify the `.env` file with your desired settings.

### Environment Variables

The following environment variables are used by the application (defined in `config/app_config.py`):

| Variable | Default | Description |
|----------|---------|-------------|
| `APP_API_HOST` | `0.0.0.0` | Host address for the FastAPI application |
| `APP_API_PORT` | `8000` | Port number for the FastAPI application |
| `APP_REDIS_HOST` | `localhost` | Hostname or IP address of the Redis server |
| `APP_REDIS_PORT` | `6379` | Port number of the Redis server |
| `APP_REDIS_DB` | `0` | Redis database number to use |
| `APP_REDIS_PASSWORD` | `None` | Password for Redis authentication (if required) |
| `APP_REDIS_MAX_CONNECTIONS` | `10` | Maximum number of connections in the Redis pool |
| `APP_REDIS_SSL` | `False` | Whether to use SSL for Redis connection |
| `APP_LOG_LEVEL` | `INFO` | Logging level (e.g., DEBUG, INFO, WARNING, ERROR, CRITICAL) |
| `APP_REDIS_CLUSTER_ENABLED` | `False` | Set to true if using Redis Cluster |
| `APP_REDIS_CLUSTER_NODES` | `localhost:7000,localhost:7001,...` | Comma-separated list of Redis cluster nodes (if cluster is enabled) |

**Note:** The application will attempt to load these from a `.env` file first, then from actual environment variables.

## Installation

1. **Clone the repository:**
   ```bash
   git clone <repository_url>
   cd device-simulation-app
   ```

2. **Create and activate a virtual environment (recommended):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Ensure Redis is running:**
   Make sure your Redis server is running and accessible based on your configuration (default: localhost:6379).

## Running the Application

To start the FastAPI server:

```bash
uvicorn app:app --host <your_host> --port <your_port> --reload
```

Replace `<your_host>` and `<your_port>` with the values configured (e.g., `0.0.0.0` and `8000` respectively, which are also the defaults if not specified via environment variables or command-line arguments). The `--reload` flag enables auto-reloading on code changes, which is useful for development.

**Example using default settings:**
```bash
uvicorn app:app --reload
```

The application will be accessible at `http://<your_host>:<your_port>` (e.g., `http://localhost:8000`).

## API Endpoints

The service provides the following main API endpoints:

- **GET /devices**: Lists all simulated devices currently stored in Redis.
- **GET /devices/{device_id}**: Retrieves detailed information for a specific device by its ID.
- **POST /devices/{device_id}/command**: Sends a command to a specific device. The device must be online. The command payload should be a JSON object with `action` (string) and `parameters` (object) fields.
  - **Example Payload**: `{"action": "set_temperature", "parameters": {"value": 22.5}}`
- **GET /health**: Provides a health check of the application, including the status of the Redis connection.

## Interactive API Documentation

Once the application is running, you can access interactive API documentation (Swagger UI and ReDoc):

- **Swagger UI**: `http://<your_host>:<your_port>/docs`
- **ReDoc**: `http://<your_host>:<your_port>/redoc`

These interfaces allow you to explore and test the API endpoints directly from your browser.

## Running Tests

The project uses pytest for testing. Tests are located in the `tests/` directory.

### Running All Tests

To run the entire test suite (excluding benchmark tests by default, as per `pytest.ini`):

```bash
pytest
```

Or with more verbosity:

```bash
pytest -v
```

### Running Specific Tests or Markers

**Run tests in a specific file:**
```bash
pytest tests/test_devices_endpoint.py
```

**Run a specific test function:**
```bash
pytest tests/test_devices_endpoint.py::test_get_devices_with_data
```

**Run tests marked with a specific marker (e.g., benchmark):**
To run benchmark tests (note: `--benchmark-disable` is in `pytest.ini`, so you might need to run them explicitly or modify `pytest.ini` for CI runs that include benchmarks):

```bash
pytest -m benchmark --benchmark-enable
```

*(The CI pipeline in `.github/workflows/tests-ci.yml` runs benchmarks with `--benchmark-disable` which means it collects them but doesn't execute the benchmark timing loops, effectively running them as standard tests. To truly benchmark, remove `--benchmark-disable` or use `--benchmark-enable`.)*

### Benchmark Tests

Benchmark tests are implemented using `pytest-benchmark`. They are marked with `@pytest.mark.benchmark`.

Refer to `pytest.ini` for how benchmarks are handled by default (`--benchmark-disable`).

### Test Reports

An HTML test report can be generated using `pytest-html` (configured in `pytest.ini`):

```bash
pytest --html=report.html --self-contained-html
```

After running, open `report.html` in your browser to view the results. The `pytest.ini` is configured to generate `report.html` by default.

## Fixture Design Decisions

Pytest fixtures (`tests/conftest.py`) are central to managing resources and test states efficiently and cleanly:

- **`event_loop` (scope: session)**: Provides a single asyncio event loop for the entire test session. This is crucial for pytest-asyncio to function correctly with session-scoped asynchronous fixtures.

- **`redis_client_fixture` (scope: function, async)**:
  - **Purpose**: Provides a clean, isolated Redis connection for each test function that needs to interact with Redis.
  - **Setup**: Connects to the Redis instance specified in the application settings (via `config.app_config`). It performs a `FLUSHDB` before yielding the client to ensure the test starts with an empty database.
  - **Teardown**: Performs another `FLUSHDB` after the test function completes to clean up any data created by the test and then closes the Redis connection.
  - **Scope**: function scope ensures that each test operates on a clean Redis state, preventing interference between tests.
  - **Asynchronous**: It's an async fixture, compatible with async test functions.

- **`test_app_client` (scope: session, autouse=True)**:
  - **Purpose**: Provides a TestClient instance for making HTTP requests to the FastAPI application.
  - **Setup**: Initializes the TestClient with the main app instance once per test session. The FastAPI application's lifespan manager (for startup/shutdown events like Redis pool initialization) is triggered when the TestClient is first used or context-managed.
  - **Teardown**: The TestClient handles its own cleanup when its context is exited at the end of the session.
  - **Scope**: session scope is efficient as the app setup is done only once. `autouse=True` means it's available to all tests without explicitly requesting it, though tests still need to list it as an argument if they use it directly.

- **`online_device_fixture` & `offline_device_fixture` (scope: function, async)**:
  - **Purpose**: Provide pre-populated device data in Redis for tests that require specific device states.
  - **Setup**: These fixtures depend on `redis_client_fixture`. They create a sample device (either online or offline) in Redis using `hset`. They yield a dictionary representing the expected API response for this device.
  - **Teardown**: Cleanup is implicitly handled by `redis_client_fixture` which flushes the database after each test.
  - **Scope**: function scope ensures that this specific device data is set up for the test that needs it and cleaned up afterwards.

### General Principles:

- **Isolation**: function-scoped fixtures for mutable resources (like Redis data) ensure tests don't affect each other.
- **Efficiency**: session-scoped fixtures for expensive, read-only resources (like the TestClient or event loop) improve test execution speed.
- **Readability**: Fixtures abstract away setup/teardown logic, making test functions cleaner and focused on the actual test logic.

## Key Design Choices and Assumptions

- **FastAPI Framework**: Chosen for its high performance, asynchronous capabilities, automatic data validation (with Pydantic), and built-in OpenAPI documentation generation.

- **Redis as Data Store**:
  - Selected for its speed and suitability for caching and storing semi-structured data like device states and command logs.
  - **Device Data**: Stored in Redis Hashes (`HSET`, `HGETALL`) for efficient retrieval of all attributes of a device. Key: `device:<device_id>`.
  - **Command History**: Stored in Redis Lists (`LPUSH`, `LRANGE`, `LTRIM`) to maintain a chronological, capped log of commands per device. Key: `device:<device_id>:commands`. A limit of 100 commands is maintained.

- **Connection Pooling**: Implemented to manage Redis connections efficiently, reducing the overhead of establishing new connections for each request.

- **Pydantic for Data Modeling**: Used for defining clear, validated data structures for API requests and responses, enhancing robustness and providing schema for OpenAPI.

- **Configuration via Environment Variables**: `pydantic-settings` is used to load configuration, allowing for easy management across different environments (dev, test, prod).

- **Lifespan Management**: FastAPI's lifespan context manager is used to initialize and clean up resources like the Redis connection pool during application startup and shutdown.

- **Asynchronous Operations**: The entire request-response cycle, including Redis interactions, is asynchronous (async/await) to maximize throughput.

- **Centralized Error Handling**: Custom exception handlers and FastAPI's built-in HTTPException are used to provide consistent error responses.

- **Test-Driven Approach**: The comprehensive test suite suggests a focus on reliability and maintainability. Tests cover API functionality, schema validation, error handling, and even startup error scenarios.

- **Simplicity of Device Simulation**: The simulation logic is kept straightforward (e.g., devices are online/offline, commands are logged). More complex device behaviors or interactions are not currently in scope.

- **Single Redis Instance Focus (with Cluster Option)**: While configuration options for Redis Cluster exist, the primary implementation and testing focus on a single Redis instance (or one accessible via a single URL for the pool).

## Continuous Integration (CI)

A CI pipeline is configured using GitHub Actions (`.github/workflows/tests-ci.yml`). This workflow:

- Triggers on pushes and pull requests to `main`, `master`, and `develop` branches.
- Sets up a specified Python version.
- Caches dependencies for faster builds.
- Installs project dependencies from `requirements.txt`.
- Starts a Redis service for the test environment.
- Runs the pytest suite, separating standard tests from benchmark tests (benchmarks are collected but not fully run to save CI time).
- Uses environment variables (e.g., `APP_REDIS_HOST`) to configure the application for the CI environment.
- Generates an HTML test report (`report.html`) for review.

This README provides a comprehensive guide to understanding, setting up, running, and testing the Device Simulator Service.